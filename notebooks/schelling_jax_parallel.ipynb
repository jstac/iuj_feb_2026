{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ebc5ac73",
   "metadata": {},
   "source": [
    "$$\n",
    "\\newcommand{\\argmax}{arg\\,max}\n",
    "\\newcommand{\\argmin}{arg\\,min}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b94eee",
   "metadata": {},
   "source": [
    "# Parallelizing the Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921e21ee",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "In the previous lectures, we implemented the Schelling segregation model using:\n",
    "\n",
    "1. [NumPy arrays and functions](https://quantecon.github.io/iuj_feb_2026/schelling_numpy.html)  \n",
    "1. [JAX with JIT compilation](https://quantecon.github.io/iuj_feb_2026/schelling_jax.html)  \n",
    "\n",
    "\n",
    "NumPy offered speed gains from vectorization.\n",
    "\n",
    "JAX was slightly faster, with some small amount of parallelization achieved.\n",
    "\n",
    "Parallelization was limited however, because the algorithm is heavily\n",
    "sequential.\n",
    "\n",
    "In this lecture,  introduce a **parallel algorithm** that\n",
    "\n",
    "- is in some sense less elegant but  \n",
    "- fully leverages JAX’s ability to perform vectorized operations across all agents simultaneously.  \n",
    "\n",
    "\n",
    "Even though the algorithm is less elegant, it still converges in a relatively\n",
    "small number of steps.\n",
    "\n",
    "Moreover, the parallel nature of the algorithm allows us to exploit the full\n",
    "power of JAX.\n",
    "\n",
    "Our plan for the lecture is to compare three implementations\n",
    "\n",
    "1. The original NumPy one,  \n",
    "1. The original JAX one, and  \n",
    "1. The new parallelized JAX algorithm.  \n",
    "\n",
    "\n",
    "We’ll run a “horse race” to see how each approach performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f6bd1e",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import random, jit, vmap\n",
    "from functools import partial\n",
    "from typing import NamedTuple\n",
    "from numpy.random import uniform\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64cd4c9",
   "metadata": {},
   "source": [
    "## Parameters\n",
    "\n",
    "We use the same parameters across all implementations. To keep our functions\n",
    "pure, we pack all parameters into a `NamedTuple` that gets passed to functions\n",
    "that need them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b6d011",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "class Params(NamedTuple):\n",
    "    num_of_type_0: int = 1800    # number of agents of type 0 (orange)\n",
    "    num_of_type_1: int = 1800    # number of agents of type 1 (green)\n",
    "    num_neighbors: int = 10      # number of neighbors\n",
    "    max_other_type: int = 6     # max number of different-type neighbors tolerated\n",
    "    num_candidates: int = 3      # candidate locations per agent per iteration\n",
    "\n",
    "\n",
    "params = Params()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d448208",
   "metadata": {},
   "source": [
    "## Shared Plotting Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7643441",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "def plot_distribution(locations, types, title):\n",
    "    \" Plot the distribution of agents. \"\n",
    "    # Convert to NumPy if needed (for JAX arrays)\n",
    "    locations_np = np.asarray(locations)\n",
    "    types_np = np.asarray(types)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    plot_args = {'markersize': 6, 'alpha': 0.8, 'markeredgecolor': 'black', 'markeredgewidth': 0.5}\n",
    "    colors = 'darkorange', 'green'\n",
    "    for agent_type, color in zip((0, 1), colors):\n",
    "        idx = (types_np == agent_type)\n",
    "        ax.plot(locations_np[idx, 0],\n",
    "                locations_np[idx, 1],\n",
    "                'o',\n",
    "                markerfacecolor=color,\n",
    "                **plot_args)\n",
    "    ax.set_title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c9a09c",
   "metadata": {},
   "source": [
    "## NumPy Implementation\n",
    "\n",
    "First, let’s copy the NumPy version from [Schelling Model with NumPy](https://quantecon.github.io/iuj_feb_2026/schelling_numpy.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb2f548",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "def np_initialize_state(params):\n",
    "    num_of_type_0, num_of_type_1 = params.num_of_type_0, params.num_of_type_1\n",
    "    n = num_of_type_0 + num_of_type_1\n",
    "    locations = uniform(size=(n, 2))\n",
    "    types = np.array([0] * num_of_type_0 + [1] * num_of_type_1)\n",
    "    return locations, types\n",
    "\n",
    "\n",
    "def np_get_distances(loc, locations):\n",
    "    return np.linalg.norm(loc - locations, axis=1)\n",
    "\n",
    "\n",
    "def np_get_neighbors(i, locations, params):\n",
    "    num_neighbors = params.num_neighbors\n",
    "    loc = locations[i, :]\n",
    "    distances = np_get_distances(loc, locations)\n",
    "    distances[i] = np.inf\n",
    "    indices = np.argsort(distances)\n",
    "    return indices[:num_neighbors]\n",
    "\n",
    "\n",
    "def np_is_happy(i, locations, types, params):\n",
    "    max_other_type = params.max_other_type\n",
    "    agent_type = types[i]\n",
    "    neighbors = np_get_neighbors(i, locations, params)\n",
    "    neighbor_types = types[neighbors]\n",
    "    num_other = np.sum(neighbor_types != agent_type)\n",
    "    return num_other <= max_other_type\n",
    "\n",
    "\n",
    "def np_update_agent(i, locations, types, params, max_attempts=10_000):\n",
    "    attempts = 0\n",
    "    while not np_is_happy(i, locations, types, params):\n",
    "        locations[i, :] = uniform(), uniform()\n",
    "        attempts += 1\n",
    "        if attempts >= max_attempts:\n",
    "            break\n",
    "\n",
    "\n",
    "def run_numpy_simulation(params, max_iter=100_000, seed=42):\n",
    "    n = params.num_of_type_0 + params.num_of_type_1\n",
    "    np.random.seed(seed)\n",
    "    locations, types = np_initialize_state(params)\n",
    "\n",
    "    plot_distribution(locations, types, 'NumPy: Initial distribution')\n",
    "\n",
    "    start_time = time.time()\n",
    "    someone_moved = True\n",
    "    iteration = 0\n",
    "    while someone_moved and iteration < max_iter:\n",
    "        print(f'Entering iteration {iteration + 1}')\n",
    "        iteration += 1\n",
    "        someone_moved = False\n",
    "        for i in range(n):\n",
    "            if not np_is_happy(i, locations, types, params):\n",
    "                np_update_agent(i, locations, types, params)\n",
    "                someone_moved = True\n",
    "    elapsed = time.time() - start_time\n",
    "\n",
    "    plot_distribution(locations, types, f'NumPy: Iteration {iteration}')\n",
    "\n",
    "    if not someone_moved:\n",
    "        print(f'Converged in {elapsed:.2f} seconds after {iteration} iterations.')\n",
    "    else:\n",
    "        print('Hit iteration bound and terminated.')\n",
    "\n",
    "    return locations, types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc8bbfb",
   "metadata": {},
   "source": [
    "## JAX Sequential Implementation\n",
    "\n",
    "Next, we copy the JAX version from [Schelling Model with JAX](https://quantecon.github.io/iuj_feb_2026/schelling_jax.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592e11b5",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "def jax_initialize_state(key, params):\n",
    "    num_of_type_0, num_of_type_1 = params.num_of_type_0, params.num_of_type_1\n",
    "    n = num_of_type_0 + num_of_type_1\n",
    "    locations = random.uniform(key, shape=(n, 2))\n",
    "    types = jnp.array([0] * num_of_type_0 + [1] * num_of_type_1)\n",
    "    return locations, types\n",
    "\n",
    "\n",
    "@jit\n",
    "def jax_get_distances(loc, locations):\n",
    "    diff = loc - locations\n",
    "    return jnp.sum(diff**2, axis=1)\n",
    "\n",
    "\n",
    "@partial(jit, static_argnames=('params',))\n",
    "def jax_get_neighbors(loc, agent_idx, locations, params):\n",
    "    num_neighbors = params.num_neighbors\n",
    "    distances = jax_get_distances(loc, locations)\n",
    "    distances = distances.at[agent_idx].set(jnp.inf)\n",
    "    _, indices = jax.lax.top_k(-distances, num_neighbors)\n",
    "    return indices\n",
    "\n",
    "\n",
    "@partial(jit, static_argnames=('params',))\n",
    "def jax_is_unhappy(loc, agent_type, agent_idx, locations, types, params):\n",
    "    max_other_type = params.max_other_type\n",
    "    neighbors = jax_get_neighbors(loc, agent_idx, locations, params)\n",
    "    neighbor_types = types[neighbors]\n",
    "    num_other = jnp.sum(neighbor_types != agent_type)\n",
    "    return num_other > max_other_type\n",
    "\n",
    "\n",
    "@partial(jit, static_argnames=('params',))\n",
    "def jax_update_agent(i, locations, types, key, params, max_attempts=10_000):\n",
    "    loc = locations[i, :]\n",
    "    agent_type = types[i]\n",
    "\n",
    "    def cond_fn(state):\n",
    "        loc, key, attempts = state\n",
    "        return (attempts < max_attempts) & jax_is_unhappy(loc, agent_type, i, locations, types, params)\n",
    "\n",
    "    def body_fn(state):\n",
    "        _, key, attempts = state\n",
    "        key, subkey = random.split(key)\n",
    "        new_loc = random.uniform(subkey, shape=(2,))\n",
    "        return new_loc, key, attempts + 1\n",
    "\n",
    "    final_loc, key, _ = jax.lax.while_loop(cond_fn, body_fn, (loc, key, 0))\n",
    "    return final_loc, key\n",
    "\n",
    "\n",
    "@partial(jit, static_argnames=('params',))\n",
    "def jax_get_unhappy_agents(locations, types, params):\n",
    "    n = params.num_of_type_0 + params.num_of_type_1\n",
    "\n",
    "    def check_agent(i):\n",
    "        return jax_is_unhappy(locations[i], types[i], i, locations, types, params)\n",
    "\n",
    "    all_unhappy = vmap(check_agent)(jnp.arange(n))\n",
    "    # jnp.where with size= returns fixed-length array (required for JIT)\n",
    "    # Pads with fill_value=-1 when fewer than n agents are unhappy\n",
    "    indices = jnp.where(all_unhappy, size=n, fill_value=-1)[0]\n",
    "    count = jnp.sum(all_unhappy)  # number of valid indices\n",
    "    return indices, count\n",
    "\n",
    "\n",
    "def jax_simulation_loop(locations, types, key, params, max_iter):\n",
    "    iteration = 0\n",
    "    while iteration < max_iter:\n",
    "        print(f'Entering iteration {iteration + 1}')\n",
    "        iteration += 1\n",
    "\n",
    "        unhappy, num_unhappy = jax_get_unhappy_agents(locations, types, params)\n",
    "\n",
    "        if num_unhappy == 0:\n",
    "            break\n",
    "\n",
    "        for j in range(int(num_unhappy)):\n",
    "            i = int(unhappy[j])\n",
    "            new_loc, key = jax_update_agent(i, locations, types, key, params)\n",
    "            locations = locations.at[i, :].set(new_loc)\n",
    "\n",
    "    return locations, iteration, key\n",
    "\n",
    "\n",
    "def run_jax_simulation(params, max_iter=100_000, seed=42):\n",
    "    key = random.PRNGKey(seed)\n",
    "    key, init_key = random.split(key)\n",
    "    locations, types = jax_initialize_state(init_key, params)\n",
    "\n",
    "    plot_distribution(locations, types, 'JAX Sequential: Initial distribution')\n",
    "\n",
    "    start_time = time.time()\n",
    "    locations, iteration, key = jax_simulation_loop(locations, types, key, params, max_iter)\n",
    "    elapsed = time.time() - start_time\n",
    "\n",
    "    plot_distribution(locations, types, f'JAX Sequential: Iteration {iteration}')\n",
    "\n",
    "    if iteration < max_iter:\n",
    "        print(f'Converged in {elapsed:.2f} seconds after {iteration} iterations.')\n",
    "    else:\n",
    "        print('Hit iteration bound and terminated.')\n",
    "\n",
    "    return locations, types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9edbebbd",
   "metadata": {},
   "source": [
    "## JAX Parallel Implementation\n",
    "\n",
    "Now we introduce the parallel algorithm.\n",
    "\n",
    "Our aim is to update all agents at the same time, rather than sequentially.\n",
    "\n",
    "To do this we\n",
    "\n",
    "1. **Identify all unhappy agents** in parallel  \n",
    "1. **Generate candidate locations** for all unhappy agents in parallel  \n",
    "1. **Test happiness** at all candidate locations in parallel  \n",
    "1. **Update all agents** simultaneously  \n",
    "\n",
    "\n",
    "Moreover, when we generate candidate locations, we will offer a fixed number to\n",
    "all agents.\n",
    "\n",
    "This allows the parallel threads to do the same amount of work, so they all run\n",
    "at the same speed.\n",
    "\n",
    "This approach is well-suited to GPU execution, where thousands of operations\n",
    "can run concurrently."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6926940f",
   "metadata": {},
   "source": [
    "### Trade-off I\n",
    "\n",
    "The sequential algorithm guarantees that each agent finds a happy location\n",
    "before moving on.\n",
    "\n",
    "The parallel algorithm instead proposes a fixed number of candidate locations\n",
    "per agent per iteration.\n",
    "\n",
    "If none of the candidates make the agent happy, the agent stays put and tries again next iteration.\n",
    "\n",
    "This means the parallel algorithm may need more iterations.\n",
    "\n",
    "However, each iteration is faster because all work is done in parallel."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74bd9f0b",
   "metadata": {},
   "source": [
    "### Trade-off II\n",
    "\n",
    "Because we update all agents at once, the agents have less information — they\n",
    "are predicting the next period distribution from the current one.\n",
    "\n",
    "(All agents take the current distribution of agents as their information, rather\n",
    "than waiting until other agents update and viewing the true distribution.)\n",
    "\n",
    "We hope that, nonetheless, the algorithm will converge."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c7672e",
   "metadata": {},
   "source": [
    "### Core Parallel Functions\n",
    "\n",
    "The `update_agent_location` function below performs all computation (generating\n",
    "candidates, checking happiness at each candidate) upfront before making the\n",
    "final decision about whether to move.\n",
    "\n",
    "This may seem wasteful for agents who are\n",
    "already happy, but it’s actually optimal for parallel execution.\n",
    "\n",
    "In SIMD/SIMT architectures (GPUs, vectorized CPU operations), all threads\n",
    "execute the same instructions in lockstep. Conditional branches like\n",
    "`jax.lax.cond` don’t skip work—both branches are computed and the result is\n",
    "selected afterward.\n",
    "\n",
    "By doing uniform work for all agents and using `jnp.where`\n",
    "to select results at the end, we align with how the hardware actually executes\n",
    "the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25bb26f3",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "@partial(jit, static_argnames=('params',))\n",
    "def update_agent_location(i, locations, types, key, params):\n",
    "    \"\"\"\n",
    "    Propose num_candidates random locations for agent i.\n",
    "    Return the first happy candidate if agent is unhappy, otherwise current location.\n",
    "    \"\"\"\n",
    "    num_candidates = params.num_candidates\n",
    "    current_loc = locations[i, :]\n",
    "    agent_type = types[i]\n",
    "\n",
    "    # Generate num_candidates random locations\n",
    "    keys = random.split(key, num_candidates)\n",
    "    candidates = vmap(lambda k: random.uniform(k, shape=(2,)))(keys)\n",
    "\n",
    "    # Check happiness at each candidate location (in parallel)\n",
    "    def check_candidate(loc):\n",
    "        return ~jax_is_unhappy(loc, agent_type, i, locations, types, params)\n",
    "    happy_at_candidates = vmap(check_candidate)(candidates)\n",
    "\n",
    "    # Find first happy candidate\n",
    "    first_happy_idx = jnp.argmax(happy_at_candidates)\n",
    "    any_happy = jnp.any(happy_at_candidates)\n",
    "    best_move_loc = candidates[first_happy_idx]\n",
    "\n",
    "    # Check if agent is already happy at current location\n",
    "    is_happy = ~jax_is_unhappy(current_loc, agent_type, i, locations, types, params)\n",
    "\n",
    "    # Move only if unhappy and found a happy candidate; otherwise stay put\n",
    "    new_loc = jnp.where(is_happy,\n",
    "                current_loc,\n",
    "                jnp.where(any_happy, best_move_loc, current_loc)\n",
    "              )\n",
    "    return new_loc\n",
    "\n",
    "\n",
    "@partial(jit, static_argnames=('params',))\n",
    "def parallel_update_step(locations, types, key, params):\n",
    "    \"\"\"\n",
    "    One step of the parallel algorithm:\n",
    "    1. Generate keys for all agents\n",
    "    2. For each agent, find a happy candidate location (in parallel)\n",
    "       (happy agents stay put, unhappy agents search for new locations)\n",
    "    \"\"\"\n",
    "    n = params.num_of_type_0 + params.num_of_type_1\n",
    "\n",
    "    # Generate keys for all agents\n",
    "    keys = random.split(key, n + 1)\n",
    "    key = keys[0]\n",
    "    agent_keys = keys[1:]\n",
    "\n",
    "    # For each agent, find a happy candidate location (in parallel)\n",
    "    def update_one_agent(i):\n",
    "        return update_agent_location(i, locations, types, agent_keys[i], params)\n",
    "    new_locations = vmap(update_one_agent)(jnp.arange(n))\n",
    "\n",
    "    return new_locations, key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cee8dbe",
   "metadata": {},
   "source": [
    "### Parallel Simulation Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef9cf4e",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "def parallel_simulation_loop(locations, types, key, params, max_iter):\n",
    "    iteration = 0\n",
    "    while iteration < max_iter:\n",
    "        print(f'Entering iteration {iteration + 1}')\n",
    "        iteration += 1\n",
    "\n",
    "        _, num_unhappy = jax_get_unhappy_agents(locations, types, params)\n",
    "\n",
    "        if num_unhappy == 0:\n",
    "            break\n",
    "\n",
    "        locations, key = parallel_update_step(locations, types, key, params)\n",
    "\n",
    "    return locations, iteration, key\n",
    "\n",
    "\n",
    "def run_parallel_simulation(params, max_iter=100_000, seed=42):\n",
    "    key = random.PRNGKey(seed)\n",
    "    key, init_key = random.split(key)\n",
    "    locations, types = jax_initialize_state(init_key, params)\n",
    "\n",
    "    plot_distribution(locations, types, 'JAX Parallel: Initial distribution')\n",
    "\n",
    "    start_time = time.time()\n",
    "    locations, iteration, key = parallel_simulation_loop(locations, types, key, params, max_iter)\n",
    "    elapsed = time.time() - start_time\n",
    "\n",
    "    plot_distribution(locations, types, f'JAX Parallel: Iteration {iteration}')\n",
    "\n",
    "    if iteration < max_iter:\n",
    "        print(f'Converged in {elapsed:.2f} seconds after {iteration} iterations.')\n",
    "    else:\n",
    "        print('Hit iteration bound and terminated.')\n",
    "\n",
    "    return locations, types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98ceaa2",
   "metadata": {},
   "source": [
    "## Warming Up JAX\n",
    "\n",
    "Before timing, we compile all JAX functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1d7091",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "key = random.PRNGKey(0)\n",
    "key, init_key = random.split(key)\n",
    "test_locations, test_types = jax_initialize_state(init_key, params)\n",
    "\n",
    "# Warm up JAX sequential functions\n",
    "_ = jax_get_distances(test_locations[0], test_locations)\n",
    "_ = jax_get_neighbors(test_locations[0], 0, test_locations, params)\n",
    "_ = jax_is_unhappy(test_locations[0], test_types[0], 0, test_locations, test_types, params)\n",
    "_, _ = jax_get_unhappy_agents(test_locations, test_types, params)\n",
    "key, subkey = random.split(key)\n",
    "_, _ = jax_update_agent(0, test_locations, test_types, subkey, params)\n",
    "\n",
    "# Warm up JAX parallel functions\n",
    "key, subkey = random.split(key)\n",
    "_ = update_agent_location(0, test_locations, test_types, subkey, params)\n",
    "key, subkey = random.split(key)\n",
    "_, _ = parallel_update_step(test_locations, test_types, subkey, params)\n",
    "\n",
    "print(\"JAX functions compiled and ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a68ca29",
   "metadata": {},
   "source": [
    "## The Horse Race\n",
    "\n",
    "Now let’s run all three implementations and compare their performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141d0fed",
   "metadata": {},
   "source": [
    "### NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f184d7c",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "print(\"=\" * 50)\n",
    "print(\"NUMPY\")\n",
    "print(\"=\" * 50)\n",
    "locations_np, types_np = run_numpy_simulation(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d673ca40",
   "metadata": {},
   "source": [
    "### JAX Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e81d55d",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "print(\"=\" * 50)\n",
    "print(\"JAX SEQUENTIAL\")\n",
    "print(\"=\" * 50)\n",
    "locations_jax, types_jax = run_jax_simulation(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd436652",
   "metadata": {},
   "source": [
    "### JAX Parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858f2958",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "print(\"=\" * 50)\n",
    "print(\"JAX PARALLEL\")\n",
    "print(\"=\" * 50)\n",
    "locations_par, types_par = run_parallel_simulation(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40701a6",
   "metadata": {},
   "source": [
    "## Discussion\n",
    "\n",
    "The results reveal interesting trade-offs:\n",
    "\n",
    "1. **NumPy** provides a straightforward implementation but runs entirely on\n",
    "  the CPU with Python loops.  \n",
    "1. **JAX Sequential** uses JIT compilation for individual operations, but the\n",
    "  outer loop still processes agents one at a time.  \n",
    "1. **JAX Parallel** processes all agents simultaneously each iteration. While\n",
    "  it may require more iterations (since agents might not find a happy location\n",
    "  in their limited candidates), each iteration leverages massive parallelism.  \n",
    "\n",
    "\n",
    "The parallel approach shines on GPUs, where thousands of threads can evaluate\n",
    "candidate locations concurrently. On CPUs, the benefits are more modest, but\n",
    "the parallel structure still allows JAX to optimize memory access patterns and\n",
    "use SIMD instructions effectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a95185",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "1. **Algorithm structure matters**: Simply porting code to JAX doesn’t\n",
    "  automatically make it faster. To fully benefit from JAX’s capabilities,\n",
    "  algorithms often need to be restructured for parallelism.  \n",
    "1. **Trade iteration count for parallelism**: The parallel algorithm may need\n",
    "  more iterations, but each iteration does more work in parallel. This\n",
    "  trade-off often favors parallelism on modern hardware.  \n",
    "1. **GPU acceleration**: The parallel algorithm is particularly well-suited\n",
    "  for GPUs, where the speedup can be dramatic. On CPU-only systems, the\n",
    "  difference is smaller.  "
   ]
  }
 ],
 "metadata": {
  "date": 1770070925.966771,
  "filename": "schelling_jax_parallel.md",
  "kernelspec": {
   "display_name": "Python",
   "language": "python3",
   "name": "python3"
  },
  "title": "Parallelizing the Algorithm"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}