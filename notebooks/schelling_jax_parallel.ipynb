{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63343a5a",
   "metadata": {},
   "source": [
    "$$\n",
    "\\newcommand{\\argmax}{arg\\,max}\n",
    "\\newcommand{\\argmin}{arg\\,min}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46453e99",
   "metadata": {},
   "source": [
    "# Schelling Model: Performance Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193c50ee",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "In the previous lectures, we implemented the Schelling segregation model using:\n",
    "\n",
    "1. [NumPy arrays and functions](https://quantecon.github.io/iuj_feb_2026/schelling_numpy.html)  \n",
    "1. [JAX with JIT compilation](https://quantecon.github.io/iuj_feb_2026/schelling_jax.html)  \n",
    "\n",
    "\n",
    "In this lecture, we compare these implementations and introduce a **parallel\n",
    "algorithm** that fully leverages JAX’s ability to perform vectorized operations\n",
    "across all agents simultaneously.\n",
    "\n",
    "We’ll run a “horse race” to see how each approach performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0dd851",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import random, jit, vmap\n",
    "from functools import partial\n",
    "from typing import NamedTuple\n",
    "from numpy.random import uniform\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1d24ef",
   "metadata": {},
   "source": [
    "## Parameters\n",
    "\n",
    "We use the same parameters across all implementations. To keep our functions\n",
    "pure, we pack all parameters into a `NamedTuple` that gets passed to functions\n",
    "that need them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae164e5a",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "class Params(NamedTuple):\n",
    "    num_of_type_0: int = 1800    # number of agents of type 0 (orange)\n",
    "    num_of_type_1: int = 1800    # number of agents of type 1 (green)\n",
    "    num_neighbors: int = 10      # number of neighbors\n",
    "    max_other_type: int = 6     # max number of different-type neighbors tolerated\n",
    "    num_candidates: int = 3      # candidate locations per agent per iteration\n",
    "\n",
    "\n",
    "params = Params()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ed50f3",
   "metadata": {},
   "source": [
    "## Shared Plotting Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a65688",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "def plot_distribution(locations, types, title):\n",
    "    \" Plot the distribution of agents. \"\n",
    "    # Convert to NumPy if needed (for JAX arrays)\n",
    "    locations_np = np.asarray(locations)\n",
    "    types_np = np.asarray(types)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    plot_args = {'markersize': 6, 'alpha': 0.8, 'markeredgecolor': 'black', 'markeredgewidth': 0.5}\n",
    "    colors = 'darkorange', 'green'\n",
    "    for agent_type, color in zip((0, 1), colors):\n",
    "        idx = (types_np == agent_type)\n",
    "        ax.plot(locations_np[idx, 0],\n",
    "                locations_np[idx, 1],\n",
    "                'o',\n",
    "                markerfacecolor=color,\n",
    "                **plot_args)\n",
    "    ax.set_title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38dfdbfc",
   "metadata": {},
   "source": [
    "## NumPy Implementation\n",
    "\n",
    "First, let’s define the NumPy version from [Schelling Model with NumPy](https://quantecon.github.io/iuj_feb_2026/schelling_numpy.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d57f93",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "def np_initialize_state(params):\n",
    "    num_of_type_0, num_of_type_1 = params.num_of_type_0, params.num_of_type_1\n",
    "    n = num_of_type_0 + num_of_type_1\n",
    "    locations = uniform(size=(n, 2))\n",
    "    types = np.array([0] * num_of_type_0 + [1] * num_of_type_1)\n",
    "    return locations, types\n",
    "\n",
    "\n",
    "def np_get_distances(loc, locations):\n",
    "    return np.linalg.norm(loc - locations, axis=1)\n",
    "\n",
    "\n",
    "def np_get_neighbors(i, locations, params):\n",
    "    num_neighbors = params.num_neighbors\n",
    "    loc = locations[i, :]\n",
    "    distances = np_get_distances(loc, locations)\n",
    "    distances[i] = np.inf\n",
    "    indices = np.argsort(distances)\n",
    "    return indices[:num_neighbors]\n",
    "\n",
    "\n",
    "def np_is_happy(i, locations, types, params):\n",
    "    max_other_type = params.max_other_type\n",
    "    agent_type = types[i]\n",
    "    neighbors = np_get_neighbors(i, locations, params)\n",
    "    neighbor_types = types[neighbors]\n",
    "    num_other = np.sum(neighbor_types != agent_type)\n",
    "    return num_other <= max_other_type\n",
    "\n",
    "\n",
    "def np_update_agent(i, locations, types, params, max_attempts=10_000):\n",
    "    attempts = 0\n",
    "    while not np_is_happy(i, locations, types, params):\n",
    "        locations[i, :] = uniform(), uniform()\n",
    "        attempts += 1\n",
    "        if attempts >= max_attempts:\n",
    "            break\n",
    "\n",
    "\n",
    "def run_numpy_simulation(params, max_iter=100_000, seed=42):\n",
    "    n = params.num_of_type_0 + params.num_of_type_1\n",
    "    np.random.seed(seed)\n",
    "    locations, types = np_initialize_state(params)\n",
    "\n",
    "    plot_distribution(locations, types, 'NumPy: Initial distribution')\n",
    "\n",
    "    start_time = time.time()\n",
    "    someone_moved = True\n",
    "    iteration = 0\n",
    "    while someone_moved and iteration < max_iter:\n",
    "        print(f'Entering iteration {iteration + 1}')\n",
    "        iteration += 1\n",
    "        someone_moved = False\n",
    "        for i in range(n):\n",
    "            if not np_is_happy(i, locations, types, params):\n",
    "                np_update_agent(i, locations, types, params)\n",
    "                someone_moved = True\n",
    "    elapsed = time.time() - start_time\n",
    "\n",
    "    plot_distribution(locations, types, f'NumPy: Iteration {iteration}')\n",
    "\n",
    "    if not someone_moved:\n",
    "        print(f'Converged in {elapsed:.2f} seconds after {iteration} iterations.')\n",
    "    else:\n",
    "        print('Hit iteration bound and terminated.')\n",
    "\n",
    "    return locations, types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0c8d0a",
   "metadata": {},
   "source": [
    "## JAX Sequential Implementation\n",
    "\n",
    "Next, the JAX version from [Schelling Model with JAX](https://quantecon.github.io/iuj_feb_2026/schelling_jax.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f1a8f4",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "def jax_initialize_state(key, params):\n",
    "    num_of_type_0, num_of_type_1 = params.num_of_type_0, params.num_of_type_1\n",
    "    n = num_of_type_0 + num_of_type_1\n",
    "    locations = random.uniform(key, shape=(n, 2))\n",
    "    types = jnp.array([0] * num_of_type_0 + [1] * num_of_type_1)\n",
    "    return locations, types\n",
    "\n",
    "\n",
    "@jit\n",
    "def jax_get_distances(loc, locations):\n",
    "    diff = loc - locations\n",
    "    return jnp.sum(diff**2, axis=1)\n",
    "\n",
    "\n",
    "@partial(jit, static_argnames=('params',))\n",
    "def jax_get_neighbors(loc, agent_idx, locations, params):\n",
    "    num_neighbors = params.num_neighbors\n",
    "    distances = jax_get_distances(loc, locations)\n",
    "    distances = distances.at[agent_idx].set(jnp.inf)\n",
    "    _, indices = jax.lax.top_k(-distances, num_neighbors)\n",
    "    return indices\n",
    "\n",
    "\n",
    "@partial(jit, static_argnames=('params',))\n",
    "def jax_is_unhappy(loc, agent_type, agent_idx, locations, types, params):\n",
    "    max_other_type = params.max_other_type\n",
    "    neighbors = jax_get_neighbors(loc, agent_idx, locations, params)\n",
    "    neighbor_types = types[neighbors]\n",
    "    num_other = jnp.sum(neighbor_types != agent_type)\n",
    "    return num_other > max_other_type\n",
    "\n",
    "\n",
    "@partial(jit, static_argnames=('params',))\n",
    "def jax_update_agent(i, locations, types, key, params, max_attempts=10_000):\n",
    "    loc = locations[i, :]\n",
    "    agent_type = types[i]\n",
    "\n",
    "    def cond_fn(state):\n",
    "        loc, key, attempts = state\n",
    "        return (attempts < max_attempts) & jax_is_unhappy(loc, agent_type, i, locations, types, params)\n",
    "\n",
    "    def body_fn(state):\n",
    "        _, key, attempts = state\n",
    "        key, subkey = random.split(key)\n",
    "        new_loc = random.uniform(subkey, shape=(2,))\n",
    "        return new_loc, key, attempts + 1\n",
    "\n",
    "    final_loc, key, _ = jax.lax.while_loop(cond_fn, body_fn, (loc, key, 0))\n",
    "    return final_loc, key\n",
    "\n",
    "\n",
    "@partial(jit, static_argnames=('params',))\n",
    "def jax_get_unhappy_agents(locations, types, params):\n",
    "    n = params.num_of_type_0 + params.num_of_type_1\n",
    "\n",
    "    def check_agent(i):\n",
    "        return jax_is_unhappy(locations[i], types[i], i, locations, types, params)\n",
    "\n",
    "    all_unhappy = vmap(check_agent)(jnp.arange(n))\n",
    "    # jnp.where with size= returns fixed-length array (required for JIT)\n",
    "    # Pads with fill_value=-1 when fewer than n agents are unhappy\n",
    "    indices = jnp.where(all_unhappy, size=n, fill_value=-1)[0]\n",
    "    count = jnp.sum(all_unhappy)  # number of valid indices\n",
    "    return indices, count\n",
    "\n",
    "\n",
    "def jax_simulation_loop(locations, types, key, params, max_iter):\n",
    "    iteration = 0\n",
    "    while iteration < max_iter:\n",
    "        print(f'Entering iteration {iteration + 1}')\n",
    "        iteration += 1\n",
    "\n",
    "        unhappy, num_unhappy = jax_get_unhappy_agents(locations, types, params)\n",
    "\n",
    "        if num_unhappy == 0:\n",
    "            break\n",
    "\n",
    "        for j in range(int(num_unhappy)):\n",
    "            i = int(unhappy[j])\n",
    "            new_loc, key = jax_update_agent(i, locations, types, key, params)\n",
    "            locations = locations.at[i, :].set(new_loc)\n",
    "\n",
    "    return locations, iteration, key\n",
    "\n",
    "\n",
    "def run_jax_simulation(params, max_iter=100_000, seed=42):\n",
    "    key = random.PRNGKey(seed)\n",
    "    key, init_key = random.split(key)\n",
    "    locations, types = jax_initialize_state(init_key, params)\n",
    "\n",
    "    plot_distribution(locations, types, 'JAX Sequential: Initial distribution')\n",
    "\n",
    "    start_time = time.time()\n",
    "    locations, iteration, key = jax_simulation_loop(locations, types, key, params, max_iter)\n",
    "    elapsed = time.time() - start_time\n",
    "\n",
    "    plot_distribution(locations, types, f'JAX Sequential: Iteration {iteration}')\n",
    "\n",
    "    if iteration < max_iter:\n",
    "        print(f'Converged in {elapsed:.2f} seconds after {iteration} iterations.')\n",
    "    else:\n",
    "        print('Hit iteration bound and terminated.')\n",
    "\n",
    "    return locations, types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c944e73",
   "metadata": {},
   "source": [
    "## JAX Parallel Implementation\n",
    "\n",
    "Now we introduce the parallel algorithm. The key insight is that instead of\n",
    "updating agents one at a time, we can:\n",
    "\n",
    "1. **Identify all unhappy agents** in parallel  \n",
    "1. **Generate candidate locations** for all unhappy agents in parallel  \n",
    "1. **Test happiness** at all candidate locations in parallel  \n",
    "1. **Update all agents** simultaneously  \n",
    "\n",
    "\n",
    "This approach is well-suited to GPU execution, where thousands of operations\n",
    "can run concurrently."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0cfaf1a",
   "metadata": {},
   "source": [
    "### The Trade-off\n",
    "\n",
    "The sequential algorithm guarantees that each agent finds a happy location\n",
    "before moving on. The parallel algorithm instead proposes a fixed number of\n",
    "candidate locations per agent per iteration. If none of the candidates make\n",
    "the agent happy, the agent stays put and tries again next iteration.\n",
    "\n",
    "This means the parallel algorithm may need more iterations, but each iteration\n",
    "is much faster because all work is done in parallel."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d9f1d0",
   "metadata": {},
   "source": [
    "### Core Parallel Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc8d003",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "@partial(jit, static_argnames=('params',))\n",
    "def find_happy_candidate(i, locations, types, key, params):\n",
    "    \"\"\"\n",
    "    Propose num_candidates random locations for agent i.\n",
    "    Return the first one where agent is happy, or current location if none work.\n",
    "    \"\"\"\n",
    "    num_candidates = params.num_candidates\n",
    "    current_loc = locations[i, :]\n",
    "    agent_type = types[i]\n",
    "\n",
    "    # Generate num_candidates random locations\n",
    "    keys = random.split(key, num_candidates)\n",
    "    candidates = vmap(lambda k: random.uniform(k, shape=(2,)))(keys)\n",
    "\n",
    "    # Check happiness at each candidate location (in parallel)\n",
    "    def check_candidate(loc):\n",
    "        return ~jax_is_unhappy(loc, agent_type, i, locations, types, params)\n",
    "\n",
    "    happy_at_candidates = vmap(check_candidate)(candidates)\n",
    "\n",
    "    # Find first happy candidate (or -1 if none)\n",
    "    first_happy_idx = jnp.argmax(happy_at_candidates)\n",
    "    any_happy = jnp.any(happy_at_candidates)\n",
    "\n",
    "    # Return first happy candidate, or current location if none are happy\n",
    "    new_loc = jnp.where(any_happy, candidates[first_happy_idx], current_loc)\n",
    "    return new_loc\n",
    "\n",
    "\n",
    "@partial(jit, static_argnames=('params',))\n",
    "def parallel_update_step(locations, types, key, params):\n",
    "    \"\"\"\n",
    "    One step of the parallel algorithm:\n",
    "    1. Generate keys for all agents\n",
    "    2. For each agent, find a happy candidate location (in parallel)\n",
    "    3. Only update unhappy agents\n",
    "    \"\"\"\n",
    "    n = params.num_of_type_0 + params.num_of_type_1\n",
    "\n",
    "    # Generate keys for all agents\n",
    "    keys = random.split(key, n + 1)\n",
    "    key = keys[0]\n",
    "    agent_keys = keys[1:]\n",
    "\n",
    "    # For each agent, find a happy candidate location (in parallel)\n",
    "    def try_move(i):\n",
    "        return find_happy_candidate(i, locations, types, agent_keys[i], params)\n",
    "\n",
    "    new_locations = vmap(try_move)(jnp.arange(n))\n",
    "\n",
    "    # Only update unhappy agents\n",
    "    def check_agent(i):\n",
    "        return jax_is_unhappy(locations[i], types[i], i, locations, types, params)\n",
    "\n",
    "    is_unhappy_mask = vmap(check_agent)(jnp.arange(n))\n",
    "\n",
    "    # Keep old location for happy agents, use new for unhappy\n",
    "    final_locations = jnp.where(is_unhappy_mask[:, None], new_locations, locations)\n",
    "\n",
    "    return final_locations, key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "191058e1",
   "metadata": {},
   "source": [
    "### Parallel Simulation Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addbaaed",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "def parallel_simulation_loop(locations, types, key, params, max_iter):\n",
    "    iteration = 0\n",
    "    while iteration < max_iter:\n",
    "        print(f'Entering iteration {iteration + 1}')\n",
    "        iteration += 1\n",
    "\n",
    "        _, num_unhappy = jax_get_unhappy_agents(locations, types, params)\n",
    "\n",
    "        if num_unhappy == 0:\n",
    "            break\n",
    "\n",
    "        locations, key = parallel_update_step(locations, types, key, params)\n",
    "\n",
    "    return locations, iteration, key\n",
    "\n",
    "\n",
    "def run_parallel_simulation(params, max_iter=100_000, seed=42):\n",
    "    key = random.PRNGKey(seed)\n",
    "    key, init_key = random.split(key)\n",
    "    locations, types = jax_initialize_state(init_key, params)\n",
    "\n",
    "    plot_distribution(locations, types, 'JAX Parallel: Initial distribution')\n",
    "\n",
    "    start_time = time.time()\n",
    "    locations, iteration, key = parallel_simulation_loop(locations, types, key, params, max_iter)\n",
    "    elapsed = time.time() - start_time\n",
    "\n",
    "    plot_distribution(locations, types, f'JAX Parallel: Iteration {iteration}')\n",
    "\n",
    "    if iteration < max_iter:\n",
    "        print(f'Converged in {elapsed:.2f} seconds after {iteration} iterations.')\n",
    "    else:\n",
    "        print('Hit iteration bound and terminated.')\n",
    "\n",
    "    return locations, types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0eb4fd5",
   "metadata": {},
   "source": [
    "## Warming Up JAX\n",
    "\n",
    "Before timing, we compile all JAX functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88af716c",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "key = random.PRNGKey(0)\n",
    "key, init_key = random.split(key)\n",
    "test_locations, test_types = jax_initialize_state(init_key, params)\n",
    "\n",
    "# Warm up JAX sequential functions\n",
    "_ = jax_get_distances(test_locations[0], test_locations)\n",
    "_ = jax_get_neighbors(test_locations[0], 0, test_locations, params)\n",
    "_ = jax_is_unhappy(test_locations[0], test_types[0], 0, test_locations, test_types, params)\n",
    "_, _ = jax_get_unhappy_agents(test_locations, test_types, params)\n",
    "key, subkey = random.split(key)\n",
    "_, _ = jax_update_agent(0, test_locations, test_types, subkey, params)\n",
    "\n",
    "# Warm up JAX parallel functions\n",
    "key, subkey = random.split(key)\n",
    "_ = find_happy_candidate(0, test_locations, test_types, subkey, params)\n",
    "key, subkey = random.split(key)\n",
    "_, _ = parallel_update_step(test_locations, test_types, subkey, params)\n",
    "\n",
    "print(\"JAX functions compiled and ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8558250",
   "metadata": {},
   "source": [
    "## The Horse Race\n",
    "\n",
    "Now let’s run all three implementations and compare their performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2baa3d",
   "metadata": {},
   "source": [
    "### NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92e30da",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "print(\"=\" * 50)\n",
    "print(\"NUMPY\")\n",
    "print(\"=\" * 50)\n",
    "locations_np, types_np = run_numpy_simulation(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ca0132",
   "metadata": {},
   "source": [
    "### JAX Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed83717b",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "print(\"=\" * 50)\n",
    "print(\"JAX SEQUENTIAL\")\n",
    "print(\"=\" * 50)\n",
    "locations_jax, types_jax = run_jax_simulation(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392bbb33",
   "metadata": {},
   "source": [
    "### JAX Parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d12aef2",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "print(\"=\" * 50)\n",
    "print(\"JAX PARALLEL\")\n",
    "print(\"=\" * 50)\n",
    "locations_par, types_par = run_parallel_simulation(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf078531",
   "metadata": {},
   "source": [
    "## Discussion\n",
    "\n",
    "The results reveal interesting trade-offs:\n",
    "\n",
    "1. **NumPy** provides a straightforward implementation but runs entirely on\n",
    "  the CPU with Python loops.  \n",
    "1. **JAX Sequential** uses JIT compilation for individual operations, but the\n",
    "  outer loop still processes agents one at a time.  \n",
    "1. **JAX Parallel** processes all agents simultaneously each iteration. While\n",
    "  it may require more iterations (since agents might not find a happy location\n",
    "  in their limited candidates), each iteration leverages massive parallelism.  \n",
    "\n",
    "\n",
    "The parallel approach shines on GPUs, where thousands of threads can evaluate\n",
    "candidate locations concurrently. On CPUs, the benefits are more modest, but\n",
    "the parallel structure still allows JAX to optimize memory access patterns and\n",
    "use SIMD instructions effectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cff8398",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "1. **Algorithm structure matters**: Simply porting code to JAX doesn’t\n",
    "  automatically make it faster. To fully benefit from JAX’s capabilities,\n",
    "  algorithms often need to be restructured for parallelism.  \n",
    "1. **Trade iteration count for parallelism**: The parallel algorithm may need\n",
    "  more iterations, but each iteration does more work in parallel. This\n",
    "  trade-off often favors parallelism on modern hardware.  \n",
    "1. **GPU acceleration**: The parallel algorithm is particularly well-suited\n",
    "  for GPUs, where the speedup can be dramatic. On CPU-only systems, the\n",
    "  difference is smaller.  "
   ]
  }
 ],
 "metadata": {
  "date": 1770012721.9205008,
  "filename": "schelling_jax_parallel.md",
  "kernelspec": {
   "display_name": "Python",
   "language": "python3",
   "name": "python3"
  },
  "title": "Schelling Model: Performance Comparison"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}