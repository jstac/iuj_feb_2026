{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0410d2e",
   "metadata": {},
   "source": [
    "$$\n",
    "\\newcommand{\\argmax}{arg\\,max}\n",
    "\\newcommand{\\argmin}{arg\\,min}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee241512",
   "metadata": {},
   "source": [
    "# Schelling Model with JAX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae585305",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "In the [previous lecture](https://quantecon.github.io/iuj_feb_2026/schelling_numpy.html), we rewrote our Schelling model\n",
    "using NumPy arrays and functions.\n",
    "\n",
    "In this lecture, we explore [JAX](https://github.com/google/jax), a library\n",
    "developed by Google for high-performance numerical computing.\n",
    "\n",
    "JAX offers several powerful features, including automatic GPU/TPU acceleration and\n",
    "just-in-time compilation.\n",
    "\n",
    "JAX is heavily used for AI workflows but we repurpose it to work with our simulation.\n",
    "\n",
    "Let’s start with some imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c833d26",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import random, jit, vmap\n",
    "from functools import partial\n",
    "from typing import NamedTuple\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b404bbb",
   "metadata": {},
   "source": [
    "## How JAX Differs from NumPy\n",
    "\n",
    "Before diving into the code, let’s understand what makes JAX special."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b09ab34",
   "metadata": {},
   "source": [
    "### Immutable Arrays\n",
    "\n",
    "In NumPy, we often modify arrays in place:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1d292c",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "# NumPy style (mutable)\n",
    "locations[i, :] = new_location  # modifies the array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07144b52",
   "metadata": {},
   "source": [
    "JAX arrays are **immutable** — they cannot be modified after creation. Instead,\n",
    "you create new arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290dd58e",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "# JAX style (immutable)\n",
    "locations = locations.at[i, :].set(new_location)  # returns a new array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4513959",
   "metadata": {},
   "source": [
    "This might seem inefficient, but JAX’s compiler can optimize these operations,\n",
    "often avoiding unnecessary copies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05fd277f",
   "metadata": {},
   "source": [
    "### Functional Programming\n",
    "\n",
    "JAX works best with **pure functions** — functions that:\n",
    "\n",
    "1. Always return the same output for the same input  \n",
    "1. Don’t modify any external state (no side effects)  \n",
    "\n",
    "\n",
    "This style makes code easier to reason about and enables JAX’s powerful\n",
    "optimizations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b9d62b",
   "metadata": {},
   "source": [
    "### Random Numbers\n",
    "\n",
    "NumPy’s random number generator maintains hidden internal state. JAX takes a\n",
    "different approach: you explicitly manage random “keys”:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40608fe5",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "# NumPy style\n",
    "np.random.seed(42)\n",
    "x = np.random.uniform()  # uses hidden state\n",
    "\n",
    "# JAX style\n",
    "key = random.PRNGKey(42)       # create a key\n",
    "x = random.uniform(key)        # pass key explicitly\n",
    "key, subkey = random.split(key)  # get new keys for future use"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a0ba23",
   "metadata": {},
   "source": [
    "This explicit handling makes JAX programs reproducible and parallelizable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707d9324",
   "metadata": {},
   "source": [
    "## Parameters\n",
    "\n",
    "We use the same parameters as before. To keep our functions pure, we pack all\n",
    "parameters into a `NamedTuple` that gets passed to functions that need them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332d86d9",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "class Params(NamedTuple):\n",
    "    num_of_type_0: int = 1000    # number of agents of type 0 (orange)\n",
    "    num_of_type_1: int = 1000    # number of agents of type 1 (green)\n",
    "    num_neighbors: int = 10      # number of agents regarded as neighbors\n",
    "    max_other_type: int = 6     # max number of different-type neighbors tolerated\n",
    "\n",
    "\n",
    "params = Params()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95744d24",
   "metadata": {},
   "source": [
    "## Initialization\n",
    "\n",
    "Here’s our initialization function. Note that we use `jax.random` instead of\n",
    "`numpy.random`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1c7398",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "def initialize_state(key, params):\n",
    "    \"\"\"\n",
    "    Initialize agent locations and types.\n",
    "\n",
    "    \"\"\"\n",
    "    num_of_type_0, num_of_type_1 = params.num_of_type_0, params.num_of_type_1\n",
    "    n = num_of_type_0 + num_of_type_1\n",
    "    locations = random.uniform(key, shape=(n, 2))\n",
    "    types = jnp.array([0] * num_of_type_0 + [1] * num_of_type_1)\n",
    "    return locations, types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2d4cac",
   "metadata": {},
   "source": [
    "The key differences from NumPy are that we pass a `key` argument to\n",
    "`random.uniform` (making random generation deterministic and reproducible)\n",
    "and we pass `params` explicitly rather than relying on global variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6a569d",
   "metadata": {},
   "source": [
    "## JAX-Compiled Functions\n",
    "\n",
    "Now let’s rewrite our core functions for JAX. We add the `@jit` decorator\n",
    "to compile functions for faster execution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9d3267",
   "metadata": {},
   "source": [
    "### Computing Distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0544eeb1",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "@jit\n",
    "def get_distances(loc, locations):\n",
    "    \"\"\"\n",
    "    Compute squared Euclidean distance from one location to all agent locations.\n",
    "\n",
    "    \"\"\"\n",
    "    diff = loc - locations  # broadcasting: (2,) - (n, 2) -> (n, 2)\n",
    "    return jnp.sum(diff**2, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45edc623",
   "metadata": {},
   "source": [
    "Notice that we use vectorized operations like in NumPy. JAX compiles these\n",
    "vectorized operations very efficiently, especially when running on GPUs.\n",
    "\n",
    "We use `jnp` (JAX NumPy) instead of `np` (NumPy). The functions are similar,\n",
    "but `jnp` operations return JAX arrays and can be compiled by JAX’s JIT\n",
    "compiler."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883cb966",
   "metadata": {},
   "source": [
    "### Finding Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2dc0b3",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "@partial(jit, static_argnames=('params',))\n",
    "def get_neighbors(loc, agent_idx, locations, params):\n",
    "    \"\"\"\n",
    "    Get indices of the num_neighbors nearest neighbors to a location (excluding agent_idx).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    loc : array of shape (2,)\n",
    "        The location to find neighbors for.\n",
    "    agent_idx : int\n",
    "        The index of the agent (excluded from neighbors).\n",
    "    locations : array of shape (n, 2)\n",
    "        All agent locations.\n",
    "    params : Params\n",
    "        Model parameters.\n",
    "    \"\"\"\n",
    "    num_neighbors = params.num_neighbors\n",
    "    distances = get_distances(loc, locations)\n",
    "    # Set self-distance to infinity so agent doesn't count as own neighbor\n",
    "    distances = distances.at[agent_idx].set(jnp.inf)\n",
    "    # Use top_k on negated distances to find num_neighbors smallest in O(n) instead of O(n log n)\n",
    "    _, indices = jax.lax.top_k(-distances, num_neighbors)\n",
    "    return indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3061222",
   "metadata": {},
   "source": [
    "Note that we use `distances.at[i].set(jnp.inf)` instead of `distances[i] = jnp.inf`\n",
    "because JAX arrays are immutable. This returns a new array with the value at\n",
    "index `i` set to infinity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8353d5fe",
   "metadata": {},
   "source": [
    "### Checking Unhappiness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175ce8fa",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "@partial(jit, static_argnames=('params',))\n",
    "def is_unhappy(loc, agent_type, agent_idx, locations, types, params):\n",
    "    \"\"\"\n",
    "    True if an agent at loc would have too many different-type neighbors.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    loc : array of shape (2,)\n",
    "        The location to test.\n",
    "    agent_type : int\n",
    "        The type of the agent (0 or 1).\n",
    "    agent_idx : int\n",
    "        The index of the agent (excluded from neighbor calculation).\n",
    "    locations : array of shape (n, 2)\n",
    "        All agent locations.\n",
    "    types : array of shape (n,)\n",
    "        All agent types.\n",
    "    params : Params\n",
    "        Model parameters.\n",
    "    \"\"\"\n",
    "    max_other_type = params.max_other_type\n",
    "    neighbors = get_neighbors(loc, agent_idx, locations, params)\n",
    "    neighbor_types = types[neighbors]\n",
    "    num_other = jnp.sum(neighbor_types != agent_type)\n",
    "    return num_other > max_other_type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb0bc43",
   "metadata": {},
   "source": [
    "This function takes the location and type as explicit arguments, rather than\n",
    "looking them up from the arrays. This design allows us to test hypothetical\n",
    "locations without modifying the `locations` array — useful when an agent is\n",
    "searching for a new location."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81821936",
   "metadata": {},
   "source": [
    "### Moving Unhappy Agents\n",
    "\n",
    "This function finds a location where the agent would be happy. Rather than\n",
    "updating the `locations` array on each iteration, it tests candidate locations\n",
    "directly and returns only the final location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c6bb21",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "@partial(jit, static_argnames=('params',))\n",
    "def update_agent(i, locations, types, key, params, max_attempts=10_000):\n",
    "    \"\"\"\n",
    "    Find a location where agent i is happy.\n",
    "\n",
    "    Returns the new location and updated random key. The calling code\n",
    "    is responsible for updating the locations array if the agent moved.\n",
    "    \"\"\"\n",
    "    loc = locations[i, :]\n",
    "    agent_type = types[i]\n",
    "\n",
    "    def cond_fn(state):\n",
    "        loc, key, attempts = state\n",
    "        return (attempts < max_attempts) & is_unhappy(loc, agent_type, i, locations, types, params)\n",
    "\n",
    "    def body_fn(state):\n",
    "        _, key, attempts = state\n",
    "        key, subkey = random.split(key)\n",
    "        new_loc = random.uniform(subkey, shape=(2,))\n",
    "        return new_loc, key, attempts + 1\n",
    "\n",
    "    final_loc, key, _ = jax.lax.while_loop(cond_fn, body_fn, (loc, key, 0))\n",
    "    return final_loc, key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2602ca9",
   "metadata": {},
   "source": [
    "Let’s break down the key JAX concepts here:\n",
    "\n",
    "1. **`jax.lax.while_loop`**: Takes three arguments:  \n",
    "  - `cond_fn(state)` — returns True to continue looping, False to stop  \n",
    "  - `body_fn(state)` — executes one iteration, returns new state  \n",
    "  - `(loc, key)` — initial state (a tuple containing location and random key)  \n",
    "1. **`random.split(key)`**: Since JAX random numbers are deterministic, we\n",
    "  need to “split” the key to get new randomness. Each split produces two new\n",
    "  keys: one to use now, one to save for later.  \n",
    "1. **Testing without updating**: By passing `loc` directly to `is_unhappy`, we\n",
    "  can test candidate locations without modifying the `locations` array. This\n",
    "  avoids creating new arrays inside the loop, improving efficiency.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f76db6",
   "metadata": {},
   "source": [
    "## Visualization\n",
    "\n",
    "Plotting uses Matplotlib, which works with regular NumPy arrays. We convert\n",
    "JAX arrays to NumPy arrays using `np.asarray()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18f4155",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "def plot_distribution(locations, types, title):\n",
    "    \"\"\"\n",
    "    Plot the distribution of agents.\n",
    "    \"\"\"\n",
    "    # Convert JAX arrays to NumPy for matplotlib\n",
    "    locations_np = np.asarray(locations)\n",
    "    types_np = np.asarray(types)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    plot_args = {'markersize': 6, 'alpha': 0.8, 'markeredgecolor': 'black', 'markeredgewidth': 0.5}\n",
    "    colors = 'darkorange', 'green'\n",
    "    for agent_type, color in zip((0, 1), colors):\n",
    "        idx = (types_np == agent_type)\n",
    "        ax.plot(locations_np[idx, 0],\n",
    "                locations_np[idx, 1],\n",
    "                'o',\n",
    "                markerfacecolor=color,\n",
    "                **plot_args)\n",
    "    ax.set_title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ddb12a",
   "metadata": {},
   "source": [
    "## The Simulation\n",
    "\n",
    "We separate the core simulation loop from the setup and plotting code. This\n",
    "makes it easier to optimize or JIT-compile the loop independently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99dc09fd",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "@partial(jit, static_argnames=('params',))\n",
    "def get_unhappy_agents(locations, types, params):\n",
    "    \"\"\"\n",
    "    Find indices and count of all unhappy agents using vectorized computation.\n",
    "    \"\"\"\n",
    "    n = params.num_of_type_0 + params.num_of_type_1\n",
    "\n",
    "    def check_agent(i):\n",
    "        return is_unhappy(locations[i], types[i], i, locations, types, params)\n",
    "\n",
    "    all_unhappy = vmap(check_agent)(jnp.arange(n))\n",
    "    # jnp.where with size= returns fixed-length array (required for JIT)\n",
    "    # Pads with fill_value=-1 when fewer than n agents are unhappy\n",
    "    indices = jnp.where(all_unhappy, size=n, fill_value=-1)[0]\n",
    "    count = jnp.sum(all_unhappy)  # number of valid indices\n",
    "    return indices, count\n",
    "\n",
    "\n",
    "def simulation_loop(locations, types, key, params, max_iter):\n",
    "    \"\"\"\n",
    "    Run the simulation loop until convergence or max iterations.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    locations : array\n",
    "        Final agent locations.\n",
    "    iteration : int\n",
    "        Number of iterations completed.\n",
    "    key : PRNGKey\n",
    "        Updated random key.\n",
    "    \"\"\"\n",
    "    iteration = 0\n",
    "    while iteration < max_iter:\n",
    "        print(f'Entering iteration {iteration + 1}')\n",
    "        iteration += 1\n",
    "\n",
    "        # Find unhappy agents using vectorized computation\n",
    "        unhappy, num_unhappy = get_unhappy_agents(locations, types, params)\n",
    "\n",
    "        # Check if everyone is happy\n",
    "        if num_unhappy == 0:\n",
    "            break\n",
    "\n",
    "        # Update only the unhappy agents\n",
    "        for j in range(int(num_unhappy)):\n",
    "            i = int(unhappy[j])\n",
    "            new_loc, key = update_agent(i, locations, types, key, params)\n",
    "            locations = locations.at[i, :].set(new_loc)\n",
    "\n",
    "    return locations, iteration, key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7e20bd",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "def run_simulation(params, max_iter=100_000, seed=42):\n",
    "    \"\"\"\n",
    "    Run the Schelling simulation using JAX.\n",
    "    \"\"\"\n",
    "    key = random.PRNGKey(seed)\n",
    "    key, init_key = random.split(key)\n",
    "    locations, types = initialize_state(init_key, params)\n",
    "\n",
    "    plot_distribution(locations, types, 'Initial distribution')\n",
    "\n",
    "    start_time = time.time()\n",
    "    locations, iteration, key = simulation_loop(locations, types, key, params, max_iter)\n",
    "    elapsed = time.time() - start_time\n",
    "\n",
    "    plot_distribution(locations, types, f'Iteration {iteration}')\n",
    "\n",
    "    if iteration < max_iter:\n",
    "        print(f'Converged in {elapsed:.2f} seconds after {iteration} iterations.')\n",
    "    else:\n",
    "        print('Hit iteration bound and terminated.')\n",
    "\n",
    "    return locations, types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0b6fb2",
   "metadata": {},
   "source": [
    "The simulation loop differs from the NumPy version in several ways:\n",
    "\n",
    "1. **Vectorized unhappiness check**: We use `get_unhappy_agents` to identify all\n",
    "  unhappy agents in parallel, then only process those agents  \n",
    "1. We pass and receive the random `key` in each call to `update_agent`  \n",
    "1. `update_agent` returns the new location, not the whole array  \n",
    "1. We only update `locations` when an agent actually moves  \n",
    "\n",
    "\n",
    "This hybrid approach uses vectorized computation to identify unhappy agents,\n",
    "then processes them sequentially. As the simulation progresses and more agents\n",
    "become happy, fewer agents need processing each iteration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11dc8825",
   "metadata": {},
   "source": [
    "## Warming Up JAX\n",
    "\n",
    "JAX compiles functions the first time they’re called. Let’s warm up the\n",
    "functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375cca59",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "# Warm up: use actual problem size to trigger compilation\n",
    "# (JAX recompiles when array shapes change)\n",
    "key = random.PRNGKey(42)\n",
    "key, init_key = random.split(key)\n",
    "test_locations, test_types = initialize_state(init_key, params)\n",
    "\n",
    "# Call each function once to compile it\n",
    "_ = get_distances(test_locations[0], test_locations)\n",
    "_ = get_neighbors(test_locations[0], 0, test_locations, params)\n",
    "_ = is_unhappy(test_locations[0], test_types[0], 0, test_locations, test_types, params)\n",
    "_, _ = get_unhappy_agents(test_locations, test_types, params)\n",
    "key, subkey = random.split(key)\n",
    "_, _ = update_agent(0, test_locations, test_types, subkey, params)\n",
    "\n",
    "print(\"JAX functions compiled and ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0ac546",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "Now let’s run the simulation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96aaa69a",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "locations, types = run_simulation(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad88e78",
   "metadata": {},
   "source": [
    "## Tips for Using JAX\n",
    "\n",
    "1. **Think functionally**: Write pure functions that don’t modify external\n",
    "  state. This makes your code easier to JIT-compile and parallelize.  \n",
    "1. **Use `jnp` instead of `np`**: Replace NumPy operations with their JAX\n",
    "  equivalents. Most functions have the same names.  \n",
    "1. **Manage random keys explicitly**: Always split keys before generating\n",
    "  random numbers. Never reuse the same key.  \n",
    "1. **Use JAX’s loop constructs**: Replace Python `for` and `while` loops with\n",
    "  `jax.lax.fori_loop` and `jax.lax.while_loop` inside JIT-compiled functions.  \n",
    "1. **Remember immutability**: Use `.at[].set()` to “update” arrays. The\n",
    "  original array is never modified.  \n",
    "1. **Warm up before timing**: Always call your functions once before measuring\n",
    "  performance to exclude compilation time.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48d6948",
   "metadata": {},
   "source": [
    "## Limitations of This Approach\n",
    "\n",
    "While this lecture demonstrated JAX syntax and concepts, the algorithm itself\n",
    "doesn’t fully leverage JAX’s parallel capabilities. The original Schelling\n",
    "algorithm has inherent sequential dependencies:\n",
    "\n",
    "- Agents update one at a time  \n",
    "- Each agent’s move changes the state for subsequent agents  \n",
    "- The “move until happy” while loop has unpredictable length  \n",
    "\n",
    "\n",
    "These characteristics don’t map well to parallel hardware like GPUs, which\n",
    "excel at performing the same operation on many data points simultaneously."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee85d8ba",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "JAX provides a powerful framework for accelerating Python code. Its key features\n",
    "are:\n",
    "\n",
    "- **Immutable arrays** that encourage functional programming  \n",
    "- **Explicit random key management** for reproducibility  \n",
    "- **JIT compilation** via the `@jit` decorator  \n",
    "- **GPU/TPU support** for hardware acceleration  \n",
    "\n",
    "\n",
    "JAX’s functional style and unique capabilities like automatic differentiation\n",
    "and seamless GPU acceleration make it particularly valuable for machine learning\n",
    "and large-scale numerical computing.\n",
    "\n",
    "To fully benefit from these capabilities, algorithms often need to be\n",
    "restructured for parallelism — as we’ll see in the next lecture."
   ]
  }
 ],
 "metadata": {
  "date": 1770012721.9049413,
  "filename": "schelling_jax.md",
  "kernelspec": {
   "display_name": "Python",
   "language": "python3",
   "name": "python3"
  },
  "title": "Schelling Model with JAX"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}